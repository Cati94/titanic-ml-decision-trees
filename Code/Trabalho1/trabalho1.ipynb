{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fa45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f4e3aed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc2266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Description:\\n', '\\n', 'The sinking of the Titanic is one of the most infamous shipwrecks in history.\\n', '\\n', 'On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\\n', '\\n', 'While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\\n', '\\n', 'In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\\n', 'Acknowledgements:\\n', '\\n', 'This dataset has been referred from Kaggle: https://www.kaggle.com/c/titanic/data.\\n', '\\n', 'For more details, check also: https://www.kaggle.com/datasets/yasserh/titanic-dataset\\n']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar txt e mostrar texto nele contido.\n",
    "try:\n",
    "    with open(\"details.txt\", \"r\", encoding=\"utf-8\") as file:  # Specify encoding if needed\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Display first few lines to understand the structure\n",
    "        print(lines)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'details.txt' was not found. Please check the file path.\")\n",
    "except UnicodeDecodeError:\n",
    "    print(\"Error: Unable to decode the file. Try specifying a different encoding (e.g., 'utf-8' or 'ISO-8859-1').\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied. Ensure the file is not locked or being used by another program.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88207f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ec2814",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd9eb42-ba85-44d8-8e1e-67fa4bafd838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,1,1,\"Cumings, Mrs. John Bradley (Florence Br...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         PassengerId  Survived  Pclass  Name  \\\n",
       "0  1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...       NaN     NaN   NaN   \n",
       "1  2,1,1,\"Cumings, Mrs. John Bradley (Florence Br...       NaN     NaN   NaN   \n",
       "2  3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,S...       NaN     NaN   NaN   \n",
       "3  4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May ...       NaN     NaN   NaN   \n",
       "4  5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,3...       NaN     NaN   NaN   \n",
       "\n",
       "   Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked  \n",
       "0  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
       "1  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
       "2  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
       "3  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
       "4  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ler csv e mostrar algumsas linhas \n",
    "df = pd.read_csv(\"Titanic-Dataset-Copy1.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3e504",
   "metadata": {},
   "source": [
    "A primeira coisa que foi executada foi a importação das bibliotecas que vão ser necessárias para este trabalho que são o Pandas e o Numpy. Após isso, procedi a uma função de leitura do csv e demopnstração do mesmo de forma simplificada  para "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d52a9",
   "metadata": {},
   "source": [
    "Tentar organizar os dados do csv por linhas e colunas com o código abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc16bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                          PassengerId  Survived  Pclass  Name  \\\n",
      "0  1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...       NaN     NaN   NaN   \n",
      "1  2,1,1,\"Cumings, Mrs. John Bradley (Florence Br...       NaN     NaN   NaN   \n",
      "2  3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,S...       NaN     NaN   NaN   \n",
      "3  4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May ...       NaN     NaN   NaN   \n",
      "4  5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,3...       NaN     NaN   NaN   \n",
      "\n",
      "   Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked  \n",
      "0  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "1  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "2  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "3  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "4  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal DataFrame:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 1: Split the 'Name' column into 'LastName' and 'FirstName'\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# The format in the CSV appears to be \"LastName, FirstName\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLastName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstName\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Clean up any extra whitespace in 'FirstName' after splitting\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Titanic-Dataset-Copy1.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Display the initial DataFrame\n",
    "print(\"Original DataFrame:\\n\", df.head())\n",
    "\n",
    "# Step 1: Split the 'Name' column into 'LastName' and 'FirstName'\n",
    "# The format in the CSV appears to be \"LastName, FirstName\"\n",
    "df[['LastName', 'FirstName']] = df['Name'].str.split(',', expand=True)\n",
    "\n",
    "# Clean up any extra whitespace in 'FirstName' after splitting\n",
    "df['FirstName'] = df['FirstName'].str.strip()\n",
    "\n",
    "# Step 2: Extract 'Deck' information from the 'Cabin' column (first letter)\n",
    "# If there are multiple cabins (e.g., \"C85 C86\"), we'll take only the first one\n",
    "df['Deck'] = df['Cabin'].str[0]  # Extract the first letter\n",
    "\n",
    "# Step 3: Convert 'Survived' to categorical labels (using .map for conversion)\n",
    "df['Survived'] = df['Survived'].map({1: 'Survived', 0: 'Did not survive'})\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(\"\\nTransformed DataFrame:\\n\", df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df074cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column data types:\n",
      " PassengerId     object\n",
      "Survived       float64\n",
      "Pclass         float64\n",
      "Name           float64\n",
      "Sex            float64\n",
      "Age            float64\n",
      "SibSp          float64\n",
      "Parch          float64\n",
      "Ticket         float64\n",
      "Fare           float64\n",
      "Cabin          float64\n",
      "Embarked       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column data types:\\n\", df.dtypes) # msostrar tipos de dados das coluinas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41937b0",
   "metadata": {},
   "source": [
    "Código que mostra valores not null pr coluna e o seu tipo de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e230c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    object \n",
      " 1   Survived     0 non-null      float64\n",
      " 2   Pclass       0 non-null      float64\n",
      " 3   Name         0 non-null      float64\n",
      " 4   Sex          0 non-null      float64\n",
      " 5   Age          0 non-null      float64\n",
      " 6   SibSp        0 non-null      float64\n",
      " 7   Parch        0 non-null      float64\n",
      " 8   Ticket       0 non-null      float64\n",
      " 9   Fare         0 non-null      float64\n",
      " 10  Cabin        0 non-null      float64\n",
      " 11  Embarked     0 non-null      float64\n",
      "dtypes: float64(11), object(1)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  #Show columns not null counts and datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a9242",
   "metadata": {},
   "source": [
    "Procura de duplicados na tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc793571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum()) #procura duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c7369",
   "metadata": {},
   "source": [
    "Standartização das strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b34268",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f6db1d4",
   "metadata": {},
   "source": [
    "Como resolver os valores NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e7e1f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values per column:\n",
      "Survived    891\n",
      "Pclass      891\n",
      "Name        891\n",
      "Sex         891\n",
      "Age         891\n",
      "SibSp       891\n",
      "Parch       891\n",
      "Ticket      891\n",
      "Fare        891\n",
      "Cabin       891\n",
      "Embarked    891\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1241: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian())\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Fill missing values in 'Column3' with the mode (assuming categorical)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Check if there are still any missing values\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMissing values after handling:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#Nan and null what i do?\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "\n",
    "# Count missing values in each column\n",
    "nan_counts = df.isna().sum()\n",
    "\n",
    "# Print columns with missing values and their counts\n",
    "print(\"NaN values per column:\")\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n",
    "# Example strategy to handle missing data\n",
    "# If 'Column1' has too many NaN values, we may drop it\n",
    "if nan_counts['Cabin'] > 0.5 * len(df):  # Adjust the threshold based on your needs\n",
    "    df = df.drop(columns=['Cabin'])\n",
    "\n",
    "# Fill missing values in 'Column2' with the median (assuming numerical)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Fill missing values in 'Column3' with the mode (assuming categorical)\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "# Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a6383",
   "metadata": {},
   "source": [
    "Como eliminar os nulos da idade e converter todos para inteiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3458a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data with NaN values:\n",
      "                                            PassengerId  Survived  Pclass  \\\n",
      "0    1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...       NaN     NaN   \n",
      "1    2,1,1,\"Cumings, Mrs. John Bradley (Florence Br...       NaN     NaN   \n",
      "2    3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,S...       NaN     NaN   \n",
      "3    4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May ...       NaN     NaN   \n",
      "4    5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,3...       NaN     NaN   \n",
      "..                                                 ...       ...     ...   \n",
      "886  887,0,2,\"Montvila, Rev. Juozas\",male,27,0,0,21...       NaN     NaN   \n",
      "887  888,1,1,\"Graham, Miss. Margaret Edith\",female,...       NaN     NaN   \n",
      "888  889,0,3,\"Johnston, Miss. Catherine Helen \"\"Car...       NaN     NaN   \n",
      "889  890,1,1,\"Behr, Mr. Karl Howell\",male,26,0,0,11...       NaN     NaN   \n",
      "890  891,0,3,\"Dooley, Mr. Patrick\",male,32,0,0,3703...       NaN     NaN   \n",
      "\n",
      "     Name  Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked  \n",
      "0     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "1     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "2     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "3     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "4     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "..    ...  ...  ...    ...    ...     ...   ...    ...       ...  \n",
      "886   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "887   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "888   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "889   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "890   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "\n",
      "[891 rows x 12 columns]\n",
      "\n",
      "Data after removing rows with NaN in Age column:\n",
      " Empty DataFrame\n",
      "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]\n",
      "Index: []\n",
      "\n",
      "Data after filling NaN values and converting to integers:\n",
      " Empty DataFrame\n",
      "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "# identifica os nan e elimina \n",
    "# Converter idades em inteiros\n",
    "\n",
    "# Step 1: Check for NaN values\n",
    "print(\"Initial data with NaN values:\\n\", df)\n",
    "\n",
    "# Step 2: Fill NaN values in 'Age' column (choose one of the following options)\n",
    "\n",
    "# Remove rows where the Age column has NaN values\n",
    "df_cleaned = df.dropna(subset=['Age'])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nData after removing rows with NaN in Age column:\\n\", df_cleaned)\n",
    "\n",
    "# Step 3: Convert 'Age' column to integer\n",
    "df_cleaned['Age'] = df_cleaned['Age'].round().astype(int)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(\"\\nData after filling NaN values and converting to integers:\\n\", df_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25f6af",
   "metadata": {},
   "source": [
    "Mostrar todo o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d240b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9f6e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d6f6224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           PassengerId  Survived  Pclass  \\\n",
      "0    1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...       NaN     NaN   \n",
      "9    10,1,2,\"Nasser, Mrs. Nicholas (Adele Achem)\",f...       NaN     NaN   \n",
      "99   100,0,2,\"Kantor, Mr. Sinai\",male,34,1,0,244367...       NaN     NaN   \n",
      "100  101,0,3,\"Petranec, Miss. Matilda\",female,28,0,...       NaN     NaN   \n",
      "101  102,0,3,\"Petroff, Mr. Pastcho (\"\"Pentcho\"\")\",m...       NaN     NaN   \n",
      "..                                                 ...       ...     ...   \n",
      "94   95,0,3,\"Coxon, Mr. Daniel\",male,59,0,0,364500,...       NaN     NaN   \n",
      "95   96,0,3,\"Shorney, Mr. Charles Joseph\",male,,0,0...       NaN     NaN   \n",
      "96   97,0,1,\"Goldschmidt, Mr. George B\",male,71,0,0...       NaN     NaN   \n",
      "97   98,1,1,\"Greenfield, Mr. William Bertram\",male,...       NaN     NaN   \n",
      "98   99,1,2,\"Doling, Mrs. John T (Ada Julia Bone)\",...       NaN     NaN   \n",
      "\n",
      "     Name  Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked  \n",
      "0     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "9     NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "99    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "100   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "101   NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "..    ...  ...  ...    ...    ...     ...   ...    ...       ...  \n",
      "94    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "95    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "96    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "97    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "98    NaN  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "\n",
    "df_cleaned.sort_values(by='PassengerId', inplace=True)\n",
    "print(df_cleaned)\n",
    "                                                    #tentativa de ordenar por PassengerId\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f9c8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9788563b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34dc77cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "915e4455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "       ..\n",
      "886   NaN\n",
      "887   NaN\n",
      "888   NaN\n",
      "889   NaN\n",
      "890   NaN\n",
      "Name: Name, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "\n",
    "print(df_cleaned['Name']) # mostrar coluna nome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc37d23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329acf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9181ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "                                          PassengerId  Survived  Pclass  Name  \\\n",
      "0  1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/...       NaN     NaN   NaN   \n",
      "1  2,1,1,\"Cumings, Mrs. John Bradley (Florence Br...       NaN     NaN   NaN   \n",
      "2  3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,S...       NaN     NaN   NaN   \n",
      "3  4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May ...       NaN     NaN   NaN   \n",
      "4  5,0,3,\"Allen, Mr. William Henry\",male,35,0,0,3...       NaN     NaN   NaN   \n",
      "\n",
      "   Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked  \n",
      "0  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "1  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "2  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "3  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "4  NaN  NaN    NaN    NaN     NaN   NaN    NaN       NaN  \n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: Name, dtype: float64\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Verify the change\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m---> 18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLastName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle_FirstName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle_FirstName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(Mr|Mrs|Miss|Master|Dr)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle_FirstName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(Mr|Mrs|Miss|Master|Dr)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Titanic-Dataset-Copy1.csv\")  # Replace with your actual file path\n",
    "\n",
    "# Display initial rows to understand the structure\n",
    "print(\"Original Data:\\n\", df.head())\n",
    "\n",
    "# Step 2: Split the 'Name' column into 'LastName' and 'Title'\n",
    "# Assuming the 'Name' column format is \"LastName, Title FirstName\" (e.g., \"Doe, Mr. John\")\n",
    "# Convert a specific column to string\n",
    "df['Title_FirstName'] = df['Name'].astype(str)\n",
    "\n",
    "# Verify the change\n",
    "print(df['Name'].head())\n",
    "\n",
    "df['LastName', 'Title_FirstName'] = df['Name'].str.split(',', expand=True)\n",
    "df['Title'] = df['Title_FirstName'].str.extract(r'\\b(Mr|Mrs|Miss|Master|Dr)\\b', expand=False)\n",
    "df['FirstName'] = df['Title_FirstName'].str.replace(r'\\b(Mr|Mrs|Miss|Master|Dr)\\b', '').str.strip()\n",
    "\n",
    "# Drop the intermediate column if not needed\n",
    "df.drop(columns=['Title_FirstName'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "632b4e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitanic-Dataset-Copy1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mlower()      \u001b[38;5;66;03m# strings lowercase standart\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "\n",
    "df['Name'] = df['Name'].str.lower()      # strings lowercase standart\n",
    "df['Sex'] = df['Sex'].str.lower()\n",
    "df['Cabin'] = df['Cabin'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272044fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitanic-Dataset-Copy1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m----> 2\u001b[0m df_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(Miss|Mr|Mrs)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df_cleaned[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMrs\u001b[39m\u001b[38;5;124m'\u001b[39m])]    \u001b[38;5;66;03m# procurar titulos em nome e devolver\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Titanic-Dataset-Copy1.csv\") \n",
    "df['Title'] = df['Name'].str.extract(r'\\b(Miss|Mr|Mrs)\\b', expand=True)\n",
    "filtered_df = df[df['Title'].isin(['Miss', 'Mr', 'Mrs'])]    # procurar titulos em nome e devolver\n",
    "print(filtered_df[['Name', 'Title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc688ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitanic-Dataset-Copy1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_cleaned\u001b[38;5;241m=\u001b[39mdf\n\u001b[1;32m----> 4\u001b[0m survival_rate \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cleaned\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m() \u001b[38;5;66;03m# taxa de sobrevivência \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvival Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msurvival_rate\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "# Calculate the survival rate\n",
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "df_cleaned=df\n",
    "survival_rate = df_cleaned('Survived')() # taxa de sobrevivência \n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d1036f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'extrat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8500\\220521538.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Titanic-Dataset-Copy1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Step 3: Extract the 'Deck' from the 'Cabin' column (first letter of each cabin string)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Assuming each cabin starts with a letter (e.g., \"C85\", \"E23\"), take the first letter as the Deck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Deck'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextrat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Step 4: Handle missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Fill missing values in 'Cabin' with 'Unknown' and in 'Embarked' with the most common value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'extrat'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Titanic-Dataset-Copy1.csv')\n",
    "# Step 3: Extract the 'Deck' from the 'Cabin' column (first letter of each cabin string)\n",
    "# Assuming each cabin starts with a letter (e.g., \"C85\", \"E23\"), take the first letter as the Deck\n",
    "df['Deck'] = df['Cabin'].extrat[0]\n",
    "\n",
    "# Step 4: Handle missing values\n",
    "# Fill missing values in 'Cabin' with 'Unknown' and in 'Embarked' with the most common value\n",
    "df['Cabin'].fillna('Unknown', inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing 'Age' values with the median age (assuming 'Age' column exists)\n",
    "if 'Age' in df.columns:\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Convert 'Fare' column to integer (if no decimals are required) or fill NaNs with median\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median()).round(0).astype(int)\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame\n",
    "df.to_csv(\"cleaned_titanic_data.csv\", index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned Data:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your original CSV data\n",
    "df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Clean the data (for example, convert a column to a string)\n",
    "df['age'] = df['age'].astype(str)\n",
    "\n",
    "# Save the cleaned DataFrame to a variable (in memory)\n",
    "cleaned_data = df\n",
    "\n",
    "# Optionally, save the cleaned DataFrame to a CSV file (for later use)\n",
    "df.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# You now have:\n",
    "# 1. `cleaned_data` variable in memory (in the current process).\n",
    "# 2. `cleaned_data.csv` file saved on disk.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
