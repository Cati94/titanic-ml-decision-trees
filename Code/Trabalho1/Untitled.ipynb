{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27ca6f-7594-46be-a579-2ddb12181439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrar txt e mostrar texto nele contido.\n",
    "try:\n",
    "    with open(\"details.txt\", \"r\", encoding=\"utf-8\") as file:  # Specify encoding if needed\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Display first few lines to understand the structure\n",
    "        print(lines)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'details.txt' was not found. Please check the file path.\")\n",
    "except UnicodeDecodeError:\n",
    "    print(\"Error: Unable to decode the file. Try specifying a different encoding (e.g., 'utf-8' or 'ISO-8859-1').\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied. Ensure the file is not locked or being used by another program.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c649d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informacao retirada do txt \n",
    "#total de pessoas a bordo e de mortos\n",
    "import re\n",
    "\n",
    "# Data from the description text (you provided earlier)\n",
    "description = \"\"\"\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\"\"\"\n",
    "\n",
    "# Use regex to find the relevant numbers\n",
    "died_pattern = r\"death of (\\d+) out of (\\d+) passengers\"\n",
    "match = re.search(died_pattern, description)\n",
    "\n",
    "if match:\n",
    "    # Extract the numbers from the match\n",
    "    died = int(match.group(1))  # Number of people who died\n",
    "    total = int(match.group(2))  # Total number of people on board\n",
    "\n",
    "    print(f\"Total number of people on board: {total}\")\n",
    "    print(f\"Number of people who died: {died}\")\n",
    "else:\n",
    "    print(\"Data not found in the text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Data from the description text (you provided earlier)\n",
    "description = \"\"\"\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\"\"\"\n",
    "\n",
    "# Extract date and question of study manually\n",
    "date = \"April 15, 1912\"\n",
    "Problem= \"RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board,\"\n",
    "question_of_study = \"What sorts of people were more likely to survive the sinking of the RMS Titanic?\"\n",
    "\n",
    "# Define the data in a dictionary\n",
    "data = {\n",
    "    'Date': [date],\n",
    "    'Problem':[Problem],\n",
    "    'Question_of_Study': [question_of_study]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfa6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Declaração da variável global\n",
    "\n",
    "import pandas as pd \n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#ler o csv de origem\n",
    "input_csv_path=\"Titanic-Dataset - copia.csv\"\n",
    "global_df=pd.read_csv(input_csv_path) # criação da variável de save data clean\n",
    "\n",
    "# Optionally set pandas display options\n",
    "pd.options.display.max_rows = 892\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "#funçao update dataframe clean\n",
    "def updateglobal_df(new_df):\n",
    " global global_df\n",
    " global_df=new_df\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the initial DataFrame from a CSV file\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"  # Replace with your actual input file name\n",
    "global_df = pd.read_csv(input_csv_path)  # Load data into the global variable\n",
    "\n",
    "def updateglobal_df(new_df):\n",
    "    \"\"\"Update the global DataFrame with the new cleaned DataFrame.\"\"\"\n",
    "    global global_df\n",
    "    global_df = new_df\n",
    "\n",
    "# Display the first few rows of the global DataFrame\n",
    "display(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print the column names (variables) from the global DataFrame\n",
    "print(\"Variables in the dataset:\", global_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa29bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print column data types from the global DataFrame\n",
    "print(\"Column data types:\\n\", global_df.dtypes)\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dcdb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Nan and null what i do?\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Count missing values in each column\n",
    "nan_counts = global_df.isna().sum()\n",
    "\n",
    "# Print columns with missing values and their counts\n",
    "print(\"NaN values per column:\")\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Mostrar txt e mostrar texto nele contido.\n",
    "try:\n",
    "    with open(\"details.txt\", \"r\", encoding=\"utf-8\") as file:  # Specify encoding if needed\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Display first few lines to understand the structure\n",
    "        print(lines)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'details.txt' was not found. Please check the file path.\")\n",
    "except UnicodeDecodeError:\n",
    "    print(\"Error: Unable to decode the file. Try specifying a different encoding (e.g., 'utf-8' or 'ISO-8859-1').\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied. Ensure the file is not locked or being used by another program.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informacao retirada do txt \n",
    "#total de pessoas a bordo e de mortos\n",
    "import re\n",
    "\n",
    "# Data from the description text (you provided earlier)\n",
    "description = \"\"\"\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\"\"\"\n",
    "\n",
    "# Use regex to find the relevant numbers\n",
    "died_pattern = r\"death of (\\d+) out of (\\d+) passengers\"\n",
    "match = re.search(died_pattern, description)\n",
    "\n",
    "if match:\n",
    "    # Extract the numbers from the match\n",
    "    died = int(match.group(1))  # Number of people who died\n",
    "    total = int(match.group(2))  # Total number of people on board\n",
    "\n",
    "    print(f\"Total number of people on board: {total}\")\n",
    "    print(f\"Number of people who died: {died}\")\n",
    "else:\n",
    "    print(\"Data not found in the text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data from the description text (you provided earlier)\n",
    "description = \"\"\"\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n",
    "\"\"\"\n",
    "\n",
    "# Extract date and question of study manually\n",
    "date = \"April 15, 1912\"\n",
    "Problem= \"RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone on board,\"\n",
    "question_of_study = \"What sorts of people were more likely to survive the sinking of the RMS Titanic?\"\n",
    "\n",
    "# Define the data in a dictionary\n",
    "data = {\n",
    "    'Date': [date],\n",
    "    'Problem':[Problem],\n",
    "    'Question_of_Study': [question_of_study]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaração da variável global\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "#ler o csv de origem\n",
    "input_csv_path=\"Titanic-Dataset - copia.csv\"\n",
    "global_df=pd.read_csv(input_csv_path) # criação da variável de save data clean\n",
    "\n",
    "# Optionally set pandas display options\n",
    "pd.options.display.max_rows = 892\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "#funçao update dataframe clean\n",
    "def updateglobal_df(new_df):\n",
    " global global_df\n",
    " global_df=new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the initial DataFrame from a CSV file\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"  # Replace with your actual input file name\n",
    "global_df = pd.read_csv(input_csv_path)  # Load data into the global variable\n",
    "\n",
    "def updateglobal_df(new_df):\n",
    "    \"\"\"Update the global DataFrame with the new cleaned DataFrame.\"\"\"\n",
    "    global global_df\n",
    "    global_df = new_df\n",
    "\n",
    "# Display the first few rows of the global DataFrame\n",
    "display(global_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4916c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print the column names (variables) from the global DataFrame\n",
    "print(\"Variables in the dataset:\", global_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba37880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print column data types from the global DataFrame\n",
    "print(\"Column data types:\\n\", global_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nan and null what i do?\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Count missing values in each column\n",
    "nan_counts = global_df.isna().sum()\n",
    "\n",
    "# Print columns with missing values and their counts\n",
    "print(\"NaN values per column:\")\n",
    "print(nan_counts[nan_counts > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db81c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "try:\n",
    "    load_csv_to_global(\"Titanic-Dataset - copia.csv\")  # Replace with your actual file\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path and try again.\")\n",
    "    global_df = None\n",
    "\n",
    "if global_df is not None:\n",
    "    try:\n",
    "        # Step 1: Check if 'Name' column exists before splitting\n",
    "        if 'Name' in global_df.columns:\n",
    "            global_df[['LastName', 'FirstName']] = global_df['Name'].str.split(',', expand=True)\n",
    "            global_df['FirstName'] = global_df['FirstName'].str.strip()  # Clean up extra spaces\n",
    "        else:\n",
    "            print(\"Error: 'Name' column is missing in the dataset.\")\n",
    "\n",
    "        # Step 2: Extract 'Deck' information from 'Cabin' (only if 'Cabin' exists)\n",
    "        if 'Cabin' in global_df.columns:\n",
    "            global_df['Deck'] = global_df['Cabin'].str[0]\n",
    "        else:\n",
    "            print(\"Error: 'Cabin' column is missing in the dataset.\")\n",
    "\n",
    "        # Step 3: Convert 'Survived' to human-readable labels (if 'Survived' exists)\n",
    "        if 'Survived' in global_df.columns:\n",
    "            global_df['Survived'] = global_df['Survived'].map({1: 'Survived', 0: 'Did not survive'})\n",
    "        else:\n",
    "            print(\"Error: 'Survived' column is missing in the dataset.\")\n",
    "\n",
    "        # Step 4: Add derived column 'FamilySize' (SibSp + Parch + 1, if both exist)\n",
    "        if 'SibSp' in global_df.columns and 'Parch' in global_df.columns:\n",
    "            global_df['FamilySize'] = global_df['SibSp'] + global_df['Parch'] + 1\n",
    "        else:\n",
    "            print(\"Error: 'SibSp' or 'Parch' column is missing, cannot compute 'FamilySize'.\")\n",
    "\n",
    "        # Step 5: Extract 'Title' from 'Name' (e.g., Mr., Mrs., Miss.)\n",
    "        if 'Name' in global_df.columns:\n",
    "            global_df['Title'] = global_df['Name'].str.extract(r',\\s*([^\\.]*)\\.', expand=False).str.strip()\n",
    "        else:\n",
    "            print(\"Error: 'Name' column is missing, cannot extract 'Title'.\")\n",
    "\n",
    "        # Display the transformed DataFrame\n",
    "        print(\"\\nTransformed DataFrame:\\n\", global_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An unexpected error occurred:\", str(e))\n",
    "\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global(\"Titanic-Dataset - copia.csv\")\n",
    "\n",
    "# Function to filter the DataFrame based on specific titles\n",
    "def filter_by_titles(titles):\n",
    "    \"\"\"\n",
    "    Filter the global DataFrame to include only rows where the 'Title' column matches the specified titles.\n",
    "\n",
    "    Args:\n",
    "        titles (list): List of titles to filter (e.g., ['Miss', 'Mr', 'Mrs']).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing only rows with the specified titles.\n",
    "    \"\"\"\n",
    "    global global_df\n",
    "    # Extract titles from the 'Name' column\n",
    "    global_df['Title'] = global_df['Name'].str.extract(r'\\b(' + '|'.join(titles) + r')\\b', expand=True)\n",
    "\n",
    "    # Filter rows to include only the specified titles\n",
    "    return global_df[global_df['Title'].isin(titles)]\n",
    "\n",
    "# Specify the list of titles to filter\n",
    "desired_titles = ['Miss', 'Mr', 'Mrs', 'Dr', 'Master']\n",
    "\n",
    "# Get the filtered DataFrame\n",
    "filtered_global_df = filter_by_titles(desired_titles)\n",
    "\n",
    "# Display the filtered DataFrame with 'Name' and 'Title' columns\n",
    "print(filtered_global_df[['Name', 'Title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e04498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Duplicates \n",
    "import pandas as pd\n",
    "\n",
    "# Define the CSV path\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "\n",
    "# Load the CSV into the global dataframe\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Optionally, set pandas display options (optional for large dataframes)\n",
    "pd.options.display.max_rows = 892\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "# Function to check and drop duplicates from the global dataframe\n",
    "def remove_duplicates_from_global_df():\n",
    "    global global_df\n",
    "    \n",
    "    # Print duplicated rows (returns boolean Series)\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(global_df.duplicated())\n",
    "\n",
    "    # Print the actual duplicated rows\n",
    "    print(\"\\nDuplicated rows in the dataframe:\")\n",
    "    print(global_df[global_df.duplicated()])\n",
    "\n",
    "    # Drop duplicates from the dataframe (inplace means changes are made directly to global_d\n",
    "    global_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Optionally, verify if any duplicates remain (this should be 0)\n",
    "    print(\"\\nDuplicated rows after dropping duplicates:\")\n",
    "    print(global_df.duplicated().sum())  # This should print 0 if no duplicates remain\n",
    "\n",
    "    # Print the cleaned dataframe (optional)\n",
    "    print(\"\\nGlobal dataframe after removing duplicates:\")\n",
    "    print(global_df)\n",
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aedadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#format string\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into the global dataframe (if not already done)\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Apply string formatting in one call\n",
    "global_df[['Name', 'Sex', 'Cabin', 'Ticket']] = global_df[['Name', 'Sex', 'Cabin', 'Ticket']].apply(\n",
    "    lambda x: x.str.title() if x.name in ['Name', 'Cabin', 'Ticket'] else x.str.lower()\n",
    ")\n",
    "\n",
    "# Print the updated dataframe to verify changes\n",
    "print(global_df[['Name', 'Sex', 'Cabin', 'Ticket']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0abcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Step 1: Read the initial DataFrame from a CSV file\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"  # Replace with your actual input file name\n",
    "global_df = pd.read_csv(input_csv_path)  # Load data into the global variable\n",
    "\n",
    "def updateglobal_df(new_df):\n",
    "    \"\"\"Update the global DataFrame with the new cleaned DataFrame.\"\"\"\n",
    "    global global_df\n",
    "    global_df = new_df\n",
    "\n",
    "# Display the first few rows of the global DataFrame\n",
    "display(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13443f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NULL in Cabin column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into the global dataframe (if not already done)\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Filter rows where the 'Cabin' column is null (NaN)\n",
    "rows_with_null_cabin = global_df[global_df['Cabin'].isnull()]\n",
    "\n",
    "# Print the filtered rows (rows where 'Cabin' is NaN)\n",
    "print(rows_with_null_cabin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the total number of passengers from the global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')\n",
    "total_passengers = len(global_df)\n",
    "print(f\"Total number of passengers on board: {total_passengers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a254733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Get the total number of passengers (number of rows in the 'global_df')\n",
    "total_passengers = len(global_df)\n",
    "\n",
    "# Assuming the total number of people (passengers + crew) is known, you can set 'total' accordingly\n",
    "# You can calculate 'total' if you have the total number of people on board. \n",
    "# Let's say 'total' is manually set or calculated from some other source.\n",
    "\n",
    "# For example, let's assume the total number of people (total) is 1,200 (passengers + crew):\n",
    "total =  2224 # This is just an example; replace with the actual total if known.\n",
    "\n",
    "# Calculate the total number of crew members\n",
    "total_crew = total - total_passengers\n",
    "\n",
    "# Print the number of crew members\n",
    "print(f\"Total number of crew members: {total_crew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Survival rate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Calculate the survival rate from the 'Survived' column\n",
    "survival_rate = global_df['Survived'].mean()  # Mean gives the proportion of 1s in the 'Survived' column\n",
    "\n",
    "# Print the survival rate as a percentage\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25975b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d72c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global(\"Titanic-Dataset - copia.csv\")\n",
    "\n",
    "# Function to filter the DataFrame based on specific titles\n",
    "def filter_by_titles(titles):\n",
    "    \"\"\"\n",
    "    Filter the global DataFrame to include only rows where the 'Title' column matches the specified titles.\n",
    "\n",
    "    Args:\n",
    "        titles (list): List of titles to filter (e.g., ['Miss', 'Mr', 'Mrs']).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing only rows with the specified titles.\n",
    "    \"\"\"\n",
    "    global global_df\n",
    "    # Extract titles from the 'Name' column\n",
    "    global_df['Title'] = global_df['Name'].str.extract(r'\\b(' + '|'.join(titles) + r')\\b', expand=True)\n",
    "\n",
    "    # Filter rows to include only the specified titles\n",
    "    return global_df[global_df['Title'].isin(titles)]\n",
    "\n",
    "# Specify the list of titles to filter\n",
    "desired_titles = ['Miss', 'Mr', 'Mrs', 'Dr', 'Master']\n",
    "\n",
    "# Get the filtered DataFrame\n",
    "filtered_global_df = filter_by_titles(desired_titles)\n",
    "\n",
    "# Display the filtered DataFrame with 'Name' and 'Title' columns\n",
    "print(filtered_global_df[['Name', 'Title']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates \n",
    "import pandas as pd\n",
    "\n",
    "# Define the CSV path\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "\n",
    "# Load the CSV into the global dataframe\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Optionally, set pandas display options (optional for large dataframes)\n",
    "pd.options.display.max_rows = 892\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "# Function to check and drop duplicates from the global dataframe\n",
    "def remove_duplicates_from_global_df():\n",
    "    global global_df\n",
    "    \n",
    "    # Print duplicated rows (returns boolean Series)\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(global_df.duplicated())\n",
    "\n",
    "    # Print the actual duplicated rows\n",
    "    print(\"\\nDuplicated rows in the dataframe:\")\n",
    "    print(global_df[global_df.duplicated()])\n",
    "\n",
    "    # Drop duplicates from the dataframe (inplace means changes are made directly to global_df)\n",
    "    global_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Optionally, verify if any duplicates remain (this should be 0)\n",
    "    print(\"\\nDuplicated rows after dropping duplicates:\")\n",
    "    print(global_df.duplicated().sum())  # This should print 0 if no duplicates remain\n",
    "\n",
    "    # Print the cleaned dataframe (optional)\n",
    "    print(\"\\nGlobal dataframe after removing duplicates:\")\n",
    "    print(global_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the CSV path\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "\n",
    "# Load the CSV into the global dataframe\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Optionally, set pandas display options (optional for large dataframes)\n",
    "pd.options.display.max_rows = 892\n",
    "pd.options.display.max_columns = 12\n",
    "\n",
    "# Function to check and drop duplicates from the global dataframe\n",
    "def remove_duplicates_from_global_df():\n",
    "    global global_df\n",
    "    \n",
    "    # Print duplicated rows (returns boolean Series)\n",
    "    print(\"Duplicated rows:\")\n",
    "    print(global_df.duplicated())\n",
    "\n",
    "    # Print the actual duplicated rows\n",
    "    print(\"\\nDuplicated rows in the dataframe:\")\n",
    "    print(global_df[global_df.duplicated()])\n",
    "\n",
    "    # Drop duplicates from the dataframe (inplace means changes are made directly to global_df)\n",
    "    global_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Optionally, verify if any duplicates remain (this should be 0)\n",
    "    print(\"\\nDuplicated rows after dropping duplicates:\")\n",
    "    print(global_df.duplicated().sum())  # This should print 0 if no duplicates remain\n",
    "\n",
    "    # Print the cleaned dataframe (optional)\n",
    "    print(\"\\nGlobal dataframe after removing duplicates:\")\n",
    "    print(global_df)\n",
    "\n",
    "# Call the function to remove duplicates\n",
    "remove_duplicates_from_global_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef31273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format string\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into the global dataframe (if not already done)\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Apply string formatting in one call\n",
    "global_df[['Name', 'Sex', 'Cabin', 'Ticket']] = global_df[['Name', 'Sex', 'Cabin', 'Ticket']].apply(\n",
    "    lambda x: x.str.title() if x.name in ['Name', 'Cabin', 'Ticket'] else x.str.lower()\n",
    ")\n",
    "\n",
    "# Print the updated dataframe to verify changes\n",
    "print(global_df[['Name', 'Sex', 'Cabin', 'Ticket']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Step 1: Read the initial DataFrame from a CSV file\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"  # Replace with your actual input file name\n",
    "global_df = pd.read_csv(input_csv_path)  # Load data into the global variable\n",
    "\n",
    "def updateglobal_df(new_df):\n",
    "    \"\"\"Update the global DataFrame with the new cleaned DataFrame.\"\"\"\n",
    "    global global_df\n",
    "    global_df = new_df\n",
    "\n",
    "# Display the first few rows of the global DataFrame\n",
    "display(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NULL in Cabin column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into the global dataframe (if not already done)\n",
    "input_csv_path = \"Titanic-Dataset - copia.csv\"\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Filter rows where the 'Cabin' column is null (NaN)\n",
    "rows_with_null_cabin = global_df[global_df['Cabin'].isnull()]\n",
    "\n",
    "# Print the filtered rows (rows where 'Cabin' is NaN)\n",
    "print(rows_with_null_cabin)\n",
    "\n",
    "\n",
    "# Get the total number of passengers from the global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')\n",
    "total_passengers = len(global_df)\n",
    "print(f\"Total number of passengers on board: {total_passengers}\")\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Get the total number of passengers (number of rows in the 'global_df')\n",
    "total_passengers = len(global_df)\n",
    "\n",
    "# Assuming the total number of people (passengers + crew) is known, you can set 'total' accordingly\n",
    "# You can calculate 'total' if you have the total number of people on board. \n",
    "# Let's say 'total' is manually set or calculated from some other source.\n",
    "\n",
    "# For example, let's assume the total number of people (total) is 1,200 (passengers + crew):\n",
    "total =  2224 # This is just an example; replace with the actual total if known.\n",
    "\n",
    "# Calculate the total number of crew members\n",
    "total_crew = total - total_passengers\n",
    "\n",
    "# Print the number of crew members\n",
    "print(f\"Total number of crew members: {total_crew}\")\n",
    "\n",
    "#Survival rate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Calculate the survival rate from the 'Survived' column\n",
    "survival_rate = global_df['Survived'].mean()  # Mean gives the proportion of 1s in the 'Survived' column\n",
    "\n",
    "# Print the survival rate as a percentage\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7654ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4853726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79035279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875dddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bef80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0cabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of passengers from the global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')\n",
    "total_passengers = len(global_df)\n",
    "print(f\"Total number of passengers on board: {total_passengers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a163635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Get the total number of passengers (number of rows in the 'global_df')\n",
    "total_passengers = len(global_df)\n",
    "\n",
    "# Assuming the total number of people (passengers + crew) is known, you can set 'total' accordingly\n",
    "# You can calculate 'total' if you have the total number of people on board. \n",
    "# Let's say 'total' is manually set or calculated from some other source.\n",
    "\n",
    "# For example, let's assume the total number of people (total) is 1,200 (passengers + crew):\n",
    "total =  2224 # This is just an example; replace with the actual total if known.\n",
    "\n",
    "# Calculate the total number of crew members\n",
    "total_crew = total - total_passengers\n",
    "\n",
    "# Print the number of crew members\n",
    "print(f\"Total number of crew members: {total_crew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Survival rate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Calculate the survival rate from the 'Survived' column\n",
    "survival_rate = global_df['Survived'].mean()  # Mean gives the proportion of 1s in the 'Survived' column\n",
    "\n",
    "# Print the survival rate as a percentage\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd77aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff42eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265037bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f128a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7eb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25956a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18badaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Get the total number of passengers (number of rows in the 'global_df')\n",
    "total_passengers = len(global_df)\n",
    "\n",
    "# Assuming the total number of people (passengers + crew) is known, you can set 'total' accordingly\n",
    "# You can calculate 'total' if you have the total number of people on board. \n",
    "# Let's say 'total' is manually set or calculated from some other source.\n",
    "\n",
    "# For example, let's assume the total number of people (total) is 1,200 (passengers + crew):\n",
    "total =  2224 # This is just an example; replace with the actual total if known.\n",
    "\n",
    "# Calculate the total number of crew members\n",
    "total_crew = total - total_passengers\n",
    "\n",
    "# Print the number of crew members\n",
    "print(f\"Total number of crew members: {total_crew}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e89e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Survival rate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Calculate the survival rate from the 'Survived' column\n",
    "survival_rate = global_df['Survived'].mean()  # Mean gives the proportion of 1s in the 'Survived' column\n",
    "\n",
    "# Print the survival rate as a percentage\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14344c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a616e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74655ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a884f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a596e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Survival rate\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the Titanic dataset is already loaded into the global dataframe\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Calculate the survival rate from the 'Survived' column\n",
    "survival_rate = global_df['Survived'].mean()  # Mean gives the proportion of 1s in the 'Survived' column\n",
    "\n",
    "# Print the survival rate as a percentage\n",
    "print(f\"Survival Rate: {survival_rate * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c94c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f96217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c643210",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44de5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datatypes origin \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe (global_df)\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the data types of each column in the global dataframe\n",
    "print(\"Data types of columns in the global dataframe:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1287d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb78404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcec189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6488d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset into the global dataframe\n",
    "input_csv_path = 'Titanic-Dataset - copia.csv'  # Adjust path if needed\n",
    "global_df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Print the original data types of the global dataframe\n",
    "print(\"Original Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Redefine column data types to optimize memory usage\n",
    "global_df = global_df.astype({\n",
    "    'Survived': 'int8',    # Survived is binary (0 or 1)\n",
    "    'Pclass': 'int8',      # Passenger class is a small integer\n",
    "    'Age': 'float32',      # Age might have decimal values\n",
    "    'SibSp': 'int8',       # Small integer for number of siblings/spouses aboard\n",
    "    'Parch': 'int8',       # Small integer for number of parents/children aboard\n",
    "    'Fare': 'float32',     # Fare can have decimal values\n",
    "    'Sex': 'category',     # Sex is a categorical variable (m/f)\n",
    "    'Embarked': 'category' # Embarked is categorical (C, Q, S)\n",
    "})\n",
    "\n",
    "# Verify the new data types\n",
    "print(\"\\nRedefined Data Types:\")\n",
    "print(global_df.dtypes)\n",
    "\n",
    "# Print the memory usage after the type conversion to show the reduction\n",
    "print(\"\\nMemory Usage (Reduced):\")\n",
    "print(global_df.memory_usage(deep=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f784d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "# global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Count NaN/None values in each column\n",
    "nan_count_per_column = global_df.isna().sum()\n",
    "\n",
    "# Count NaN/None values in the entire DataFrame\n",
    "nan_count_total = global_df.isna().sum().sum()\n",
    "\n",
    "# Output the results\n",
    "print(\"NaN/None values per column:\")\n",
    "print(nan_count_per_column)\n",
    "\n",
    "print(\"\\nTotal NaN/None values in the DataFrame:\", nan_count_total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607eb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Step 1: Fill missing values in 'Age' with the median and convert 'Age' to an integer\n",
    "global_df['Age'] = global_df['Age'].fillna(global_df['Age'].median()).round().astype(int)\n",
    "\n",
    "# Step 2: Fill missing values in 'Embarked' with the mode (most frequent value)\n",
    "global_df['Embarked'] = global_df['Embarked'].fillna(global_df['Embarked'].mode()[0])\n",
    "\n",
    "# Step 3: Check if there are still any missing values\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 4: Print the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2710386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Ensure that the Ticket column is treated as a string in case of any numeric tickets\n",
    "global_df['Ticket'] = global_df['Ticket'].astype(str)\n",
    "\n",
    "# Extract the first letter from the 'Ticket' column to represent the deck (making sure it's a valid deck letter)\n",
    "global_df['Ticket_Deck'] = global_df['Ticket'].str[0].str.upper()\n",
    "\n",
    "# Check if 'Ticket_Deck' is actually a valid deck letter (e.g., A, B, C, etc.)\n",
    "valid_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
    "global_df['Ticket_Deck'] = global_df['Ticket_Deck'].apply(lambda x: x if x in valid_decks else None)\n",
    "\n",
    "# Fill missing 'Cabin' values with the 'Ticket_Deck' (deck letter), but only if the deck letter is valid\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna(global_df['Ticket_Deck'])\n",
    "\n",
    "# Optional: Drop the 'Ticket_Deck' column if you no longer need it\n",
    "global_df.drop(columns=['Ticket_Deck'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame (you can check for missing values here as well)\n",
    "print(global_df)\n",
    "\n",
    "# Optionally, you can check for remaining missing values in the 'Cabin' column after filling\n",
    "print(\"\\nRemaining missing values in 'Cabin' column:\", global_df['Cabin'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262b48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming global_df is already loaded, or load the dataset into global_df\n",
    "global_df = pd.read_csv('Titanic-Dataset - copia.csv')  # Already loaded\n",
    "\n",
    "# Replace NaN/None values in 'Cabin' with 'Unknown'\n",
    "global_df['Cabin'] = global_df['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Apply the transformation: Make all 'Cabin' values uppercase\n",
    "global_df['Cabin'] = global_df['Cabin'].apply(lambda x: x.upper())\n",
    "\n",
    "# Display the updated DataFrame (first few rows)\n",
    "print(\"\\nDataFrame after filling NaN values and transforming 'Cabin':\")\n",
    "print(global_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    " \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "global global_df\n",
    "global_df = pd.read_csv(file_path)\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "# Print DataFrame information from the global DataFrame\n",
    " print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "     global global_df\n",
    "     \n",
    "     updateglobal_df(global_df)\n",
    "     # Update the global_df with the cleaned data\n",
    "     global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "     # Step 4: Check for remaining missing values after cleaning (optional)\n",
    "     print(\"\\nMissing values after handling:\")\n",
    "     # Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "     print(global_df.isna().sum())\n",
    "     # Confirm the file has been saved\n",
    "     print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "     \n",
    "     output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "     global_df.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ef56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the dataset into the global variable\n",
    "def load_csv_to_global(file_path):\n",
    "    \"\"\"Load a CSV file into the global DataFrame variable.\"\"\"\n",
    "    global global_df\n",
    "    global_df = pd.read_csv(file_path)\n",
    "\n",
    "# Load the Titanic dataset\n",
    "load_csv_to_global('Titanic-Dataset - copia.csv')\n",
    "\n",
    "# Print DataFrame information from the global DataFrame\n",
    "print(global_df.info())\n",
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Function to update global dataframe (after cleaning)\n",
    "def updateglobal_df(new_df):\n",
    "    global global_df\n",
    "    global_df = new_df  # Update the global_df variable with the cleaned data\n",
    "\n",
    "# Update the global_df with the cleaned data\n",
    "updateglobal_df(global_df)\n",
    "\n",
    "# Step 4: Check for remaining missing values after cleaning (optional)\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(global_df.isna().sum())\n",
    "\n",
    "# Step 5: Save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_path = \"cleaned_datafinal.csv\"  # Specify the desired output file name\n",
    "global_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Cleaned data saved to {output_csv_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
